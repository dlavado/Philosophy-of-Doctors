# Description: config file for default parameters of scenenet_ts40k experiment
# Author: Diogo Mateus

program: main.py
method: bayes
metric:
  goal: maximize
  name: val_MulticlassJaccardIndex
project: 'GIBLi-SOA'
##############################
parameters:
  output_dir: 
    value: '${experiment_path}/outputs'
  # ------------------ #
  # dataset config
  # ------------------ #
  dataset:
    value: 'ts40k'
  preprocessed:
    value: True
  load_into_memory:
    value: True
  add_normals:
    value: False
  data_path:
    value: ''
  num_classes:
    value: 6
  num_data_channels:
    value: 3
  batch_size:
    value: 3
  ignore_index:
    value: -1
  num_workers: 
    value: 0
  val_split:
    value: 0.1
  # ------------------ #
  # model config
  # ------------------ #
  model:
    value: 'pt_transformer'
  in_channels:
    value: 3
  model_version:
    value: 'gibli-v3'
  gib_dict:
    parameters:
      h-ellip:
        max: 8
        min: 1
        distribution: int_uniform
      h-disk:
        max: 8
        min: 1
        distribution: int_uniform
      h-cone:
        max: 8
        min: 1
        distribution: int_uniform
      ellip:
        max: 8
        min: 1
        distribution: int_uniform
      h-cy:
        max: 8
        min: 1
        distribution: int_uniform
      disk:
        max: 8
        min: 1
        distribution: int_uniform
      cone:
        max: 8
        min: 1
        distribution: int_uniform
      cy:
        max: 8
        min: 1
        distribution: int_uniform
  num_observers:
    values: [[8], [16], [32]]
  kernel_reach:
    max: 1.0
    min: 0.1
    distribution: uniform
  neighbor_size:
    values: [[16, 32], [8, 16], [8, 32], [8, 8, 8], [8, 8, 16]]
  out_channels:
    values: [16, 32, 64]
  model_hash:
    value: 'ptv3-gibli-gib${gib_dict}-obs${num_observers}-neigh${neighbor_size}-out${out_channels}'
  # ------------------ #
  # training config
  # ------------------ #
  optimizer:
    value: 'adamw'
  learning_rate:
     values: [0.0001, 0.00005, 0.00001, 0.000005, 0.000001]
  max_epochs:
    value: 30
  accelerator:
    value: 'gpu'
  devices:
    value: -1
  num_nodes:
    value: 1
  strategy:
    value: 'auto'
  early_stop_metric:
    value: 'val_MulticlassJaccardIndex'
  # ------------------ #
  # criterion addons config
  # ------------------ #
  criterion:
    value: 'cross_entropy'
  class_weights:
    value: True
  segmentation_losses:
    parameters:
      tversky:
        max: 1.0
        min: 0.1
        distribution: uniform
      lovasz:
        max: 1.0
        min: 0.1
        distribution: uniform
      focal:
        max: 1.0
        min: 0.1
        distribution: uniform
  # ------------------ #
  # Lit Trainer config
  # ------------------ #
  fast_dev_run:
    value: True
  precision:
    value: 32
  auto_lr_find:
    value: False
  auto_scale_batch_size:
    value: False
  profiler:
    value: False
  accumulate_grad_batches:
    # values: [2, 4, 8, 16]
    value: 16
  save_onnx:
    value: False
  # ------------------ #
  # Checkpoint config
  # ------------------ #
  resume_from_checkpoint:
    value: False
  checkpoint_dir:
    value: '${experiment_path}/checkpoints/'
  resume_checkpoint_name:
    value: MulticlassJaccardIndex
  checkpoint_every_n_epochs:
    value: 1
  checkpoint_every_n_steps:
    value: 0
#######################################
early_terminate:
  type: hyperband
  min_iter: 3
  eta: 3
command:
  - python3
  - ${program}
  - --wandb_sweep
  - --dataset
  - ts40k
  - --model
  - pt-gibli
  - --arch
  - ptv3
  - --resumable
