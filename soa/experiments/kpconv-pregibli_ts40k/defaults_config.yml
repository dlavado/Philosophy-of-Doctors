
# Description: config file for default parameters of scenenet_ts40k experiment
# Author: Diogo Mateus

project:
  value: 'TS40K'
output_dir: 
  value: '${experiment_path}/outputs'
# ------------------ #
# dataset config
# ------------------ #
dataset:
  value: 'ts40k'
preprocessed:
  value: True
  description: 'If True, uses the preprocessed the dataset'
load_into_memory:
  value: False
add_normals:
  value: False
  description: 'If True, adds normals to the dataset'
data_path:
  value: ''
num_classes:
  value: 6
num_data_channels:
  value: 3
  description: 'Number of channels in the dataset'
batch_size:
  value: 1
ignore_index:
  value: 0 # noise
num_workers: 
  value: 0
val_split:
  value: 0.1
test_split:
  value: 0.3
fps_points:
  value: 10000
min_points:
  value: null
  description: 'Number of points to sample from the point cloud with farthest point sampling'
# ------------------ #
# model config
# ------------------ #
model:
  value: 'kpconv-pregibli'
model_hash:
  value: 'stg5_ksize15_r12_s2.0_pregibli_gib4_ob-1_nknn4_nknn4'
in_channels:
  value: 3 # xyz coords
  description: 'Number of channels in the input'
num_stages:
    value: 5
kpconv_voxel_size:
    value: 0.02
kernel_size:
    value: 15
kpconv_radius:
    value: 12
kpconv_sigma:
    value: 2.0
init_dim:
    value: 64
neighbor_limits:
    value: "[10, 10, 10, 10, 10]" # if None, recompute neighbors
#### GIBLi Parameters ####
gib_dict:
  value: {
    'cy'    : 4,
    'ellip' : 4,
    'disk'  : 4,
    'cone'  : 4,
  }
  description: 'Dictionary of GIBs'
num_observers:
  value: -1
kernel_size:
  value: 0.1
# --- GIBLi config
num_levels:
  value: 4
  description: 'Number of levels in the model'
out_gib_channels:
  value: "4" #"[8, 16, 32, 32]"
  description: 'Number of output channels for GIB' 
skip_connections:
  value: True
  description: 'Whether to use skip connections in the model'
graph_strategy:
  value: 'grid' # 'fps' or 'grid'
  description: 'Strategy for graph construction'
graph_pooling_factor:
  value: 2
  description: 'Pooling factor for graph operations'
neighborhood_strategy:
  value: 'knn'
  description: 'Strategy for neighborhood operations'
neighborhood_size:
  value: "4" # "[16, 16, 16, 16]" # "[16, 48, 96, 192, 384]"
  description: 'Size of the neighborhood for the strategy'
neighborhood_kwargs:
  value: {}
  description: 'Additional keyword arguments for neighborhood operations'
neighborhood_update_kwargs:
  value: {}
  description: 'Additional keyword arguments for neighborhood updates'
voxel_size:
  value: "[0.05, 0.05, 0.05]"
  description: 'Voxel size for voxelization'
# ------------------ #
# training config
# ------------------ #
optimizer:
  value: 'adamw' #'adam' 
learning_rate:
  value: 0.0001
max_epochs:
  value: 100 # -1 for infinite
accelerator:
  value: 'gpu' # 'ddp' or 'dp'
devices:
  value: -1 # -1 for all available gpus
num_nodes:
  value: 1
strategy:
  value: 'auto' # 'ddp'
early_stop_metric:
  value: 'val_MulticlassJaccardIndex'
# ------------------ #
# criterion addons config
# ------------------ #
criterion:
  value: 'cross_entropy' # this is not in use
  description: 'Loss function' # this is not in use since pointnet models have their own loss function
class_weights:
  value: True
  description: 'Use class weights in the loss function'
segmentation_losses:
  value: null #{'focal': 0.2, 'tversky': 0.2, 'lovasz': 0.2}
  description: 'Additional losses for segmentation'
# ------------------ #
# Lit Trainer config
# ------------------ #
fast_dev_run:
  value: True
precision: # 16 or 32 FPU precision
  value: 16
  description: 'FPU precision'
auto_lr_find:
  value: False
auto_scale_batch_size:
  value: False
profiler:
  value: False
  description: 'PyTorch Lightning profiler'
accumulate_grad_batches:
  value: 1
  description: 'Accumulate gradients on k batches before performing a backward pass'
save_onnx:
  value: False
  description: 'Save model in onnx format'
# ------------------ #
# Checkpoint config
# ------------------ #
resume_from_checkpoint:
  value: False
checkpoint_dir:
  value: '${experiment_path}/checkpoints'
resume_checkpoint_name:
  value: MulticlassJaccardIndex-v1 # 'FbetaScore', 'train_loss', last, 'best', 'F1Score'
checkpoint_every_n_epochs: # This parameter and the next one are mutually exclusive
  value: 1 # every n epochs
checkpoint_every_n_steps:
  value: 0 # every n steps
  
